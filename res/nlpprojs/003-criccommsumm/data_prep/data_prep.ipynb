{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_paths = glob.glob(\"data/Commentaries/*.csv\")\n",
    "len(comm_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_paths = glob.glob(\"data/Reports/*.txt\")\n",
    "len(report_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_fno = []\n",
    "for i in comm_paths:\n",
    "    fno = int(i.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "    comm_fno.append(fno)\n",
    "\n",
    "report_fno = []\n",
    "for j in report_paths:\n",
    "    fno = int(j.split(\"\\\\\")[-1].replace(\"report\", \"\").split(\".\")[0])\n",
    "    report_fno.append(fno)\n",
    "\n",
    "comm_fno = set(comm_fno)\n",
    "report_fno = set(report_fno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_read_fno = list(comm_fno.intersection(report_fno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_read_paths = []\n",
    "for i in comm_paths:\n",
    "    fno = int(i.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "    if fno in to_read_fno:\n",
    "        comm_read_paths.append(i)\n",
    "\n",
    "report_read_paths = []\n",
    "for j in report_paths:\n",
    "    fno = int(j.split(\"\\\\\")[-1].replace(\"report\", \"\").split(\".\")[0])\n",
    "    if fno in to_read_fno:\n",
    "        report_read_paths.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(comm_read_paths) == len(report_read_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commentary_read(path):\n",
    "    test_str_lst = pd.read_csv(path)[\"Data\"].to_list()\n",
    "    comm_inp_lst = []\n",
    "    cnt = 0\n",
    "    for i in test_str_lst:\n",
    "        j = i.lower()\n",
    "        if \"run\" not in j:\n",
    "            if cnt==0 or cnt>=len(test_str_lst)-3:\n",
    "                comm_inp_lst.append(i)\n",
    "            elif \" bye \" not in j and \" wide \" not in j and \"extra\" not in j:\n",
    "                if \" out \" in j:\n",
    "                    comm_inp_lst.append(i)\n",
    "                elif \"wicket\" in j:\n",
    "                    comm_inp_lst.append(i)\n",
    "            else:\n",
    "                if random.choice([0,1]) == 1:\n",
    "                    comm_inp_lst.append(i)\n",
    "        elif \" six \" in j:\n",
    "            if random.choice([0,1,0,0]) == 1:\n",
    "                comm_inp_lst.append(i)\n",
    "        cnt = cnt + 1\n",
    "    return ' '.join(comm_inp_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_read(path):\n",
    "    with open(path) as f:\n",
    "        report_str = f.read()\n",
    "    return report_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_commentaries = []\n",
    "final_reports = []\n",
    "for i in comm_read_paths:\n",
    "    final_commentaries.append(commentary_read(i))\n",
    "for j in report_read_paths:\n",
    "    final_reports.append(report_read(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame({\n",
    "    \"Commentary_Highlights\" : final_commentaries,\n",
    "    \"Match_Report\" : final_reports\n",
    "})\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_parquet(\"data/match_report_gen.parquet\", index=False)\n",
    "final_df.to_csv(\"data/match_report_gen.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"src_len\"] = final_df[\"Commentary_Highlights\"].map(lambda x : len(tokenizer(x)[\"input_ids\"]))\n",
    "final_df[\"tgt_len\"] = final_df[\"Match_Report\"].map(lambda x : len(tokenizer(x)[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"Commentary_Highlights\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(final_df[\"src_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"data_new_T5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"src_len\"] = df[\"input_text\"].map(lambda x : len(tokenizer(x)[\"input_ids\"]))\n",
    "df[\"tgt_len\"] = df[\"target_text\"].map(lambda x : len(tokenizer(x)[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nhv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
